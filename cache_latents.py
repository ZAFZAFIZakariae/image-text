"""Pre-compute VAE latents compatible with kohya_ss trainers."""

from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Iterable

import numpy as np
import torch
from PIL import Image
from tqdm.auto import tqdm

from text2image_pipeline import _load_vae as load_vae_helper


def parse_args(argv: Iterable[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Encode dataset images with the same VAE preprocessing that kohya_ss "
            "expects so cached latents can be reused during training."
        )
    )
    parser.add_argument(
        "dataset_path",
        type=Path,
        help=(
            "Directory containing the training images and a metadata.jsonl manifest "
            "(generated by prepare_text_image_dataset.py)."
        ),
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=None,
        help=(
            "Where latent .npz files should be stored. Defaults to <dataset_path>/latents."
        ),
    )
    parser.add_argument(
        "--image-size",
        type=int,
        default=512,
        help="Resize images to this resolution before encoding (default: 512).",
    )
    parser.add_argument(
        "--center-crop",
        action="store_true",
        help="Match kohya's optional center cropping behaviour before resizing.",
    )
    parser.add_argument(
        "--vae",
        type=str,
        default="stabilityai/sd-vae-ft-mse",
        help=(
            "Model identifier or local path pointing to the AutoencoderKL weights "
            "that should be used for encoding (default: stabilityai/sd-vae-ft-mse)."
        ),
    )
    parser.add_argument(
        "--vae-variant",
        type=str,
        default=None,
        help="Optional diffusers variant (e.g. fp16) to request when loading the VAE.",
    )
    parser.add_argument(
        "--device",
        type=str,
        default=None,
        help="Torch device to run on (default: cuda when available else cpu).",
    )
    parser.add_argument(
        "--deterministic",
        action="store_true",
        help="Store the mean of the latent distribution instead of sampling.",
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="Recompute latents even when an output file already exists.",
    )
    return parser.parse_args(list(argv) if argv is not None else None)


def load_manifest(dataset_path: Path) -> list[tuple[Path, str]]:
    manifest_path = dataset_path / "metadata.jsonl"
    if not manifest_path.exists():
        raise FileNotFoundError(
            f"Could not locate metadata.jsonl in {dataset_path}. "
            "Use prepare_text_image_dataset.py to generate it."
        )

    entries: list[tuple[Path, str]] = []
    with manifest_path.open("r", encoding="utf-8") as handle:
        for line_number, line in enumerate(handle, start=1):
            record = json.loads(line)
            try:
                image_rel = Path(record["file"])
            except KeyError as exc:  # pragma: no cover - defensive
                raise KeyError(
                    f"Malformed entry on line {line_number} of {manifest_path}: missing {exc.args[0]!r}"
                ) from exc

            image_path = dataset_path / image_rel
            if not image_path.exists():
                raise FileNotFoundError(
                    f"Image referenced on line {line_number} does not exist: {image_path}"
                )

            entries.append((image_path, image_rel.stem))

    if not entries:
        raise ValueError(f"No records were found inside {manifest_path}.")

    return entries


def preprocess_image(path: Path, size: int, center_crop: bool) -> torch.FloatTensor:
    image = Image.open(path).convert("RGB")

    if center_crop:
        width, height = image.size
        min_dimension = min(width, height)
        left = (width - min_dimension) // 2
        top = (height - min_dimension) // 2
        image = image.crop((left, top, left + min_dimension, top + min_dimension))

    image = image.resize((size, size), resample=Image.BICUBIC)
    image_array = np.asarray(image, dtype=np.float32) / 255.0
    image_tensor = torch.from_numpy(image_array).permute(2, 0, 1)
    image_tensor = image_tensor * 2.0 - 1.0
    return image_tensor


def encode_latents(
    vae: torch.nn.Module,
    pixel_values: torch.FloatTensor,
    device: torch.device,
    deterministic: bool,
) -> np.ndarray:
    with torch.no_grad():
        batch = pixel_values.unsqueeze(0).to(device)
        if vae.dtype in {torch.float16, torch.bfloat16}:  # pragma: no cover - depends on hardware
            batch = batch.to(vae.dtype)
        encoded = vae.encode(batch).latent_dist
        latents = encoded.mean if deterministic else encoded.sample()
        latents = latents * vae.config.scaling_factor
    latents = latents[0].to(torch.float32).cpu().numpy()
    return latents


def resolve_device(explicit: str | None) -> torch.device:
    if explicit is not None:
        return torch.device(explicit)
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


def main(argv: Iterable[str] | None = None) -> int:
    args = parse_args(argv)

    dataset_path = args.dataset_path.resolve()
    if not dataset_path.exists():
        raise FileNotFoundError(f"Dataset directory does not exist: {dataset_path}")

    output_dir = args.output_dir or (dataset_path / "latents")
    output_dir = output_dir.resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    entries = load_manifest(dataset_path)

    device = resolve_device(args.device)
    torch_dtype = torch.float16 if device.type == "cuda" else torch.float32
    vae = load_vae_helper(args.vae, args.vae_variant, torch_dtype, str(device))
    vae.eval()

    # store latents in deterministic dtype to avoid drift when resuming
    for image_path, stem in tqdm(entries, desc="Encoding latents", unit="image"):
        output_path = output_dir / f"{stem}.npz"
        if output_path.exists() and not args.overwrite:
            continue

        pixel_values = preprocess_image(image_path, args.image_size, args.center_crop)
        latents = encode_latents(vae, pixel_values, device, args.deterministic)
        np.savez_compressed(output_path, latents=latents)

    return 0


if __name__ == "__main__":  # pragma: no cover - CLI entry point
    raise SystemExit(main())
